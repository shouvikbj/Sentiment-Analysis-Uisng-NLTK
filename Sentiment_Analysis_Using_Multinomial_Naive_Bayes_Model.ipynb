{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_Using_Multinomial_Naive_Bayes_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8_xK3-DVx7Oc"
      },
      "outputs": [],
      "source": [
        "X_train = [\n",
        "  \"This was awesome an awesome movie\",\n",
        "  \"Great movie! I liked it a lot\",\n",
        "  \"Happy Ending! awesome acting by the hero\",\n",
        "  \"loved it! truly great\",\n",
        "  \"bad not up to the mark\",\n",
        "  \"could have been better\",\n",
        "  \"Surely a Disappointing movie\"\n",
        "]\n",
        "\n",
        "y_train = [1,1,1,1,0,0,0] # 1 - Positive, 0 - Negative class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GCbVDeuwOA_",
        "outputId": "7e26b25c-6297-4bc5-e456-d5728437ed2c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This was awesome an awesome movie',\n",
              " 'Great movie! I liked it a lot',\n",
              " 'Happy Ending! awesome acting by the hero',\n",
              " 'loved it! truly great',\n",
              " 'bad not up to the mark',\n",
              " 'could have been better',\n",
              " 'Surely a Disappointing movie']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "8zP_tbmewfj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "metadata": {
        "id": "VkeYlu2nwXzw"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "DZWVk7eXwla2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7dpF8ikwvkI",
        "outputId": "3b80181f-34e9-4d4a-bfb8-9bd3d7e78709"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "en_stopwords = set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "kIhDk8IMw1Ks"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getCleanedText(text):\n",
        "  text = text.lower()\n",
        "\n",
        "  # tokenize\n",
        "  tokens = tokenizer.tokenize(text)\n",
        "  new_tokens = [token for token in tokens if token not in en_stopwords]\n",
        "\n",
        "  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]\n",
        "\n",
        "  clean_text = \" \".join(stemmed_tokens)\n",
        "\n",
        "  return clean_text"
      ],
      "metadata": {
        "id": "aqSP1mFRxItY"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data to be tested on\n",
        "\n",
        "X_test = [\n",
        "  \"I was happy & happy and I loved the acting in the movie\",\n",
        "  \"The movie I saw was bad\"\n",
        "]\n",
        "\n",
        "# cleaning the train and test data\n",
        "\n",
        "X_clean = [getCleanedText(i) for i in X_train]\n",
        "Xt_clean = [getCleanedText(i) for i in X_test]"
      ],
      "metadata": {
        "id": "-m3Qucrxx3Tp"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_clean"
      ],
      "metadata": {
        "id": "-vlAucXTylzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "961c41cc-306c-4482-c8e1-5f4d8e5f8944"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['awesom awesom movi',\n",
              " 'great movi like lot',\n",
              " 'happi end awesom act hero',\n",
              " 'love truli great',\n",
              " 'bad mark',\n",
              " 'could better',\n",
              " 'sure disappoint movi']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "jvcFSRb38FUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "m-bm_wKG8BOO"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(ngram_range=(1,2))"
      ],
      "metadata": {
        "id": "QWTAIm2S8RGo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vec = cv.fit_transform(X_clean).toarray()"
      ],
      "metadata": {
        "id": "hZa9bviY8hb2"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8RNhKah8ro2",
        "outputId": "7e216a90-40b4-405f-cce6-68afdd8a333c"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "        1, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 1, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cv.get_feature_names_out())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLTj0es38sxU",
        "outputId": "320dac95-e2cb-49ca-8f41-e4df929de2fb"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['act' 'act hero' 'awesom' 'awesom act' 'awesom awesom' 'awesom movi'\n",
            " 'bad' 'bad mark' 'better' 'could' 'could better' 'disappoint'\n",
            " 'disappoint movi' 'end' 'end awesom' 'great' 'great movi' 'happi'\n",
            " 'happi end' 'hero' 'like' 'like lot' 'lot' 'love' 'love truli' 'mark'\n",
            " 'movi' 'movi like' 'sure' 'sure disappoint' 'truli' 'truli great']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xt_vect = cv.transform(Xt_clean).toarray()"
      ],
      "metadata": {
        "id": "a32e6Exq8w_9"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "cG2rYd4m9ERO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing Multinomial Naive Bayes Model\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "metadata": {
        "id": "XZ0mRuD29Cvr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the instance of the model\n",
        "\n",
        "mn = MultinomialNB()"
      ],
      "metadata": {
        "id": "lQ_-2w-59N2R"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fitting data to the model\n",
        "\n",
        "mn.fit(X_vec, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa6ellUV9wdv",
        "outputId": "29ea2a98-b3b7-4691-99ce-6ca9983fe95c"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting sentiments on the test data\n",
        "\n",
        "y_pred = mn.predict(Xt_vect)"
      ],
      "metadata": {
        "id": "FY_vNueu92f9"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# viewing the predctions\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn7Obxcv9-m8",
        "outputId": "544cb157-0af4-43fd-a7d3-dc5e80682245"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5VKFH9TE-FOc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}