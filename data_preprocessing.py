# -*- coding: utf-8 -*-
"""data_preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HdP2ktN1ainZXYL0VfKQzQNEo7nVUE5V
"""

from sklearn.datasets import fetch_20newsgroups

text_data = fetch_20newsgroups()

# type(text_data)
import numpy as np

raw_text = text_data.data[:4]
raw_text

"""# Stage 1 -> Convert to lower text"""

clean_text_1 = []

def to_lower_case(data):
  for words in data:
    clean_text_1.append(str.lower(words))

to_lower_case(raw_text)

clean_text_1

"""# Stage 2 -> Tokenize"""

clean_text_2 = []

from nltk.tokenize import sent_tokenize, word_tokenize

import nltk
nltk.download("punkt")

sent_tok = []
for sent in clean_text_1:
  sent = sent_tokenize(sent)
  sent_tok.append(sent)

sent_tok

# word tokenize

clean_text_2 = [word_tokenize(i) for i in clean_text_1]

clean_text_2

"""# Stage 3 -> Remove Special Characters"""

import re

clean_text_3 = []

for words in clean_text_2:
  clean = []
  for w in words:
    res = re.sub(r'[^\w\s]', "", w)
    if res != "":
      clean.append(res)
    clean_text_3.append(clean)

clean_text_3

"""# Stage 4 -> Stop Word Removal"""

import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords

clean_text_4 = []

for words in clean_text_3:
  w = []
  for word in words:
    if not word in stopwords.words('english'):
      w.append(word)
    clean_text_4.append(w)

clean_text_4

"""# Stage 5 -> Stemming"""

from nltk.stem.porter import PorterStemmer

port = PorterStemmer()

## This is how Stemmer works

# a = [port.stem(i) for i in ["reading", "washing", "wash", "driving"]]
# a

clean_text_5 = []

for words in clean_text_4:
  w = []
  for word in words:
    w.append(word)
  clean_text_5.append(w)

clean_text_5

"""Lemmatization"""

from nltk.stem.wordnet import WordNetLemmatizer

wnet = WordNetLemmatizer()

import nltk
nltk.download('wordnet')

lem = []

for words in clean_text_4:
  w = []
  for word in words:
    w.append(wnet.lemmatize(word))
  lem.append(w)

lem

print(clean_text_5[:1])

