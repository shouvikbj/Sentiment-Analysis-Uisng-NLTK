# -*- coding: utf-8 -*-
"""Sentiment_Analysis_Using_Multinomial_Naive_Bayes_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DiTkpCS2LoWC4zjLRUu0FHoT1v_z1tON
"""

X_train = [
  "This was awesome an awesome movie",
  "Great movie! I liked it a lot",
  "Happy Ending! awesome acting by the hero",
  "loved it! truly great",
  "bad not up to the mark",
  "could have been better",
  "Surely a Disappointing movie"
]

y_train = [1,1,1,1,0,0,0] # 1 - Positive, 0 - Negative class

X_train

"""# Data cleaning"""

from nltk.tokenize import RegexpTokenizer

from nltk.stem.porter import PorterStemmer
from nltk.corpus import stopwords

import nltk
nltk.download("stopwords")

tokenizer = RegexpTokenizer(r"\w+")
en_stopwords = set(stopwords.words("english"))
ps = PorterStemmer()

def getCleanedText(text):
  text = text.lower()

  # tokenize
  tokens = tokenizer.tokenize(text)
  new_tokens = [token for token in tokens if token not in en_stopwords]

  stemmed_tokens = [ps.stem(tokens) for tokens in new_tokens]

  clean_text = " ".join(stemmed_tokens)

  return clean_text

# data to be tested on

X_test = [
  "I was happy & happy and I loved the acting in the movie",
  "The movie I saw was bad"
]

# cleaning the train and test data

X_clean = [getCleanedText(i) for i in X_train]
Xt_clean = [getCleanedText(i) for i in X_test]

X_clean

"""# Vectorization"""

from sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer(ngram_range=(1,2))

X_vec = cv.fit_transform(X_clean).toarray()

X_vec

print(cv.get_feature_names_out())

Xt_vect = cv.transform(Xt_clean).toarray()

"""# Multinomial Naive Bayes"""

# importing Multinomial Naive Bayes Model

from sklearn.naive_bayes import MultinomialNB

# creating the instance of the model

mn = MultinomialNB()

# fitting data to the model

mn.fit(X_vec, y_train)

# predicting sentiments on the test data

y_pred = mn.predict(Xt_vect)

# viewing the predctions

y_pred

